{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24309,"status":"ok","timestamp":1707998092410,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"XnYh9GRJwjqn","outputId":"efb18064-13f5-4176-8db2-6e8454dc292e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive as drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8532,"status":"ok","timestamp":1707998100935,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"HQgqu005ibWB","outputId":"52e4fefa-6781-4053-9d2c-4aa580ba085c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Cloning into 'Brain-CT-Hemorrhage-Dataset'...\n","remote: Enumerating objects: 6760, done.\u001b[K\n","remote: Total 6760 (delta 0), reused 0 (delta 0), pack-reused 6760\u001b[K\n","Receiving objects: 100% (6760/6760), 125.66 MiB | 20.16 MiB/s, done.\n","Resolving deltas: 100% (108/108), done.\n","Updating files: 100% (7696/7696), done.\n"]}],"source":["# Access a public Github repos\n","!rm -rf /content/Brain-CT-Hemorrhage-Dataset # remove git clone\n","%cd '/content'\n","!git clone https://github.com/ricardotran92/Brain-CT-Hemorrhage-Dataset.git"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":635,"status":"ok","timestamp":1707998101565,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"rt0TbSG0j4_h"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1707998101566,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"B2yXnEZZieIH"},"outputs":[],"source":["# @title\n","def DataSetSummary (local_path, tabs):\n","  # Take list of files & folders in local folder\n","  all_items = os.listdir(local_path)\n","\n","  # Filter folder list\n","  folders = [item for item in all_items if os.path.isdir(os.path.join(local_path, item))]\n","\n","  # Print summary information if folders > 0:\n","  if(len(folders) > 0):\n","    indent = '\\t' * tabs\n","    print(\"{}Tổng số thư mục: {}\".format(indent, len(folders)))\n","    for folder in folders:\n","      folder_path = os.path.join(local_path, folder)\n","      files_in_folder = len(os.listdir(folder_path))\n","      print(\"{}-Thư mục: {}, Số tệp: {}\".format(indent, folder, files_in_folder))\n","      DataSetSummary(folder_path, tabs+1)\n","\n","# DataSetSummary(local_path, 0)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1707998101566,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"GYIAhM3xXdaG","outputId":"ba8f295e-fb60-4cdd-a29c-778cf03a5908"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tổng số thư mục: 2\n","-Thư mục: NORMAL, Số tệp: 27\n","\tTổng số thư mục: 27\n","\t-Thư mục: N23[N23], Số tệp: 134\n","\t-Thư mục: N6[N6], Số tệp: 135\n","\t-Thư mục: N1[N1], Số tệp: 232\n","\t-Thư mục: N13[N13], Số tệp: 128\n","\t-Thư mục: N18[N18], Số tệp: 217\n","\t-Thư mục: N17[N17], Số tệp: 140\n","\t-Thư mục: N27[N27], Số tệp: 136\n","\t-Thư mục: N8[N8], Số tệp: 63\n","\t-Thư mục: N25[N25], Số tệp: 123\n","\t-Thư mục: N22[N22], Số tệp: 228\n","\t-Thư mục: N15[N15], Số tệp: 132\n","\t-Thư mục: N19[N19], Số tệp: 112\n","\t-Thư mục: N14[N14], Số tệp: 46\n","\t-Thư mục: N24[N24], Số tệp: 132\n","\t-Thư mục: N10[N10], Số tệp: 122\n","\t-Thư mục: N20[N20], Số tệp: 255\n","\t-Thư mục: N21[N21], Số tệp: 131\n","\t-Thư mục: N12[N12], Số tệp: 130\n","\t-Thư mục: N11[N11], Số tệp: 128\n","\t-Thư mục: N3[N3], Số tệp: 360\n","\t-Thư mục: N4[N4], Số tệp: 126\n","\t-Thư mục: N2[N2], Số tệp: 238\n","\t-Thư mục: N5[N5], Số tệp: 127\n","\t-Thư mục: N9[N9], Số tệp: 138\n","\t-Thư mục: N16[N16], Số tệp: 131\n","\t-Thư mục: N26[N26], Số tệp: 129\n","\t-Thư mục: N7[N7], Số tệp: 132\n","-Thư mục: Hemorrhagic, Số tệp: 1\n","\tTổng số thư mục: 1\n","\t-Thư mục: KANAMA, Số tệp: 18\n","\t\tTổng số thư mục: 18\n","\t\t-Thư mục: 21[21] _2, Số tệp: 45\n","\t\t-Thư mục: 5[5], Số tệp: 127\n","\t\t-Thư mục: 19[19], Số tệp: 23\n","\t\t-Thư mục: 17[17]__, Số tệp: 195\n","\t\t-Thư mục: 15[15], Số tệp: 196\n","\t\t-Thư mục: 3[3], Số tệp: 82\n","\t\t-Thư mục: 11[11], Số tệp: 204\n","\t\t-Thư mục: 7[7], Số tệp: 134\n","\t\t-Thư mục: 13[13], Số tệp: 221\n","\t\t-Thư mục: 14[14], Số tệp: 130\n","\t\t-Thư mục: 4[4], Số tệp: 232\n","\t\t-Thư mục: 9[9], Số tệp: 123\n","\t\t-Thư mục: 20[20]_2, Số tệp: 123\n","\t\t-Thư mục: 8[8], Số tệp: 138\n","\t\t-Thư mục: 12[12], Số tệp: 203\n","\t\t-Thư mục: 6[6], Số tệp: 132\n","\t\t-Thư mục: 1[1], Số tệp: 212\n","\t\t-Thư mục: 2[2], Số tệp: 170\n","Tổng số thư mục: 2\n","-Thư mục: NORMAL, Số tệp: 27\n","\tTổng số thư mục: 27\n","\t-Thư mục: N23[N23], Số tệp: 20\n","\t-Thư mục: N6[N6], Số tệp: 20\n","\t-Thư mục: N1[N1], Số tệp: 20\n","\t-Thư mục: N13[N13], Số tệp: 20\n","\t-Thư mục: N18[N18], Số tệp: 20\n","\t-Thư mục: N17[N17], Số tệp: 20\n","\t-Thư mục: N27[N27], Số tệp: 20\n","\t-Thư mục: N8[N8], Số tệp: 20\n","\t-Thư mục: N25[N25], Số tệp: 20\n","\t-Thư mục: N22[N22], Số tệp: 20\n","\t-Thư mục: N15[N15], Số tệp: 20\n","\t-Thư mục: N19[N19], Số tệp: 20\n","\t-Thư mục: N14[N14], Số tệp: 20\n","\t-Thư mục: N24[N24], Số tệp: 20\n","\t-Thư mục: N10[N10], Số tệp: 20\n","\t-Thư mục: N20[N20], Số tệp: 20\n","\t-Thư mục: N21[N21], Số tệp: 20\n","\t-Thư mục: N12[N12], Số tệp: 20\n","\t-Thư mục: N11[N11], Số tệp: 20\n","\t-Thư mục: N3[N3], Số tệp: 20\n","\t-Thư mục: N4[N4], Số tệp: 20\n","\t-Thư mục: N2[N2], Số tệp: 20\n","\t-Thư mục: N5[N5], Số tệp: 20\n","\t-Thư mục: N9[N9], Số tệp: 20\n","\t-Thư mục: N16[N16], Số tệp: 20\n","\t-Thư mục: N26[N26], Số tệp: 20\n","\t-Thư mục: N7[N7], Số tệp: 20\n","-Thư mục: Hemorrhagic, Số tệp: 1\n","\tTổng số thư mục: 1\n","\t-Thư mục: KANAMA, Số tệp: 18\n","\t\tTổng số thư mục: 18\n","\t\t-Thư mục: 21[21] _2, Số tệp: 20\n","\t\t-Thư mục: 5[5], Số tệp: 20\n","\t\t-Thư mục: 19[19], Số tệp: 20\n","\t\t-Thư mục: 17[17]__, Số tệp: 20\n","\t\t-Thư mục: 15[15], Số tệp: 20\n","\t\t-Thư mục: 3[3], Số tệp: 20\n","\t\t-Thư mục: 11[11], Số tệp: 20\n","\t\t-Thư mục: 7[7], Số tệp: 20\n","\t\t-Thư mục: 13[13], Số tệp: 20\n","\t\t-Thư mục: 14[14], Số tệp: 20\n","\t\t-Thư mục: 4[4], Số tệp: 20\n","\t\t-Thư mục: 9[9], Số tệp: 20\n","\t\t-Thư mục: 20[20]_2, Số tệp: 20\n","\t\t-Thư mục: 8[8], Số tệp: 20\n","\t\t-Thư mục: 12[12], Số tệp: 20\n","\t\t-Thư mục: 6[6], Số tệp: 20\n","\t\t-Thư mục: 1[1], Số tệp: 20\n","\t\t-Thư mục: 2[2], Số tệp: 20\n"]}],"source":["# import os\n","\n","# Hierarchical local folder in Colab\n","repository_folder = [\"Brain-CT-Hemorrhage-Dataset\"]\n","\n","for folder in repository_folder:\n","  local_path = '/content/' + folder + '/dataset'\n","  DataSetSummary(local_path, 0)\n","  local_path = '/content/' + folder + '/sample'\n","  DataSetSummary(local_path, 0)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1707998102012,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"efQhF0Bbg79e","outputId":"66cbe1ce-ae72-46cb-ffb7-4a9373bc6552"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Thesis/Preprocessing/Brain-CT-Hemorrhage-Dataset\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/Thesis/Preprocessing/Brain-CT-Hemorrhage-Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707998102013,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"o14rIQa6JFpM"},"outputs":[],"source":["# Set the path to your dataset\n","dataset_path = '/content/Brain-CT-Hemorrhage-Dataset/sample'\n","# dataset_path = '/content/Brain-CT-Hemorrhage-Dataset/dataset'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707977229707,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"jfblIIt2UuJp","outputId":"33050b21-9398-467a-8c14-396de8695077"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/Brain-CT-Hemorrhage-Dataset/dataset\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N23[N23]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N6[N6]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N1[N1]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N13[N13]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N18[N18]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N17[N17]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N27[N27]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N8[N8]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N25[N25]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N22[N22]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N15[N15]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N19[N19]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N14[N14]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N24[N24]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N10[N10]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N20[N20]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N21[N21]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N12[N12]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N11[N11]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N3[N3]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N4[N4]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N2[N2]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N5[N5]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N9[N9]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N16[N16]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N26[N26]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/NORMAL/N7[N7]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/21[21] _2\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/5[5]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/19[19]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/17[17]__\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/15[15]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/3[3]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/11[11]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/7[7]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/13[13]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/14[14]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/4[4]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/9[9]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/20[20]_2\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/8[8]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/12[12]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/6[6]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/1[1]\n","/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/2[2]\n"]}],"source":["import os\n","\n","def list_dirs_recursively(path, seen=None):\n","    if seen is None:\n","        seen = set()\n","\n","    for dirpath, dirnames, filenames in os.walk(path):\n","        if dirpath not in seen:\n","            print(f'{dirpath}')\n","            seen.add(dirpath)\n","            for dirname in dirnames:\n","                list_dirs_recursively(os.path.join(dirpath, dirname), seen)\n","\n","dataset_path = '/content/Brain-CT-Hemorrhage-Dataset/dataset'\n","list_dirs_recursively(dataset_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1CIpZWjBWAoHyACejsKO_3nKl7WMTcDIC"},"executionInfo":{"elapsed":22507,"status":"ok","timestamp":1707976126427,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"jIIRvwZ6vfZh","outputId":"2c28f539-4093-40e4-b96e-fe90b898844c"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["class Image:\n","    def __init__(self, path, label):\n","        # self.image = cv2.imread(path) # directly read\n","        self.path = path # only directory\n","        self.label = label\n","\n","def load_images_from_folder(dataset_path, images_per_class=None):\n","    images = {}\n","    for class_name in os.listdir(dataset_path):\n","        class_folder_path = os.path.join(dataset_path, class_name)\n","        if os.path.isdir(class_folder_path):\n","            count = 0\n","            images[class_name] = []\n","            for image_name in os.listdir(class_folder_path):\n","                if images_per_class is None or count < images_per_class:\n","                    image_path = os.path.join(class_folder_path, image_name)\n","                    img = Image(image_path, class_name)\n","                    images[class_name].append(img)\n","                    count += 1\n","    return images\n","\n","def imshow(images, images_per_class=None):\n","    for class_name, imgs in images.items():\n","        plt.figure(figsize=(30,30))\n","        print(f'Class {class_name}')\n","        for i in range(min(images_per_class if images_per_class else len(imgs), len(imgs))):\n","            plt.subplot(1, images_per_class if images_per_class else len(imgs), i+1)\n","            img = cv2.imread(imgs[i].path)\n","            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            plt.imshow(img)\n","            # plt.title(os.path.basename(imgs[i].path))\n","            plt.axis('off')\n","        plt.show()\n","\n","# Example usage:\n","images = load_images_from_folder('/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA')\n","imshow(images, 10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707976146332,"user":{"displayName":"Quang Hùng Trần (Gruff Taurus)","userId":"07073966798361037030"},"user_tz":-420},"id":"BJgJ4r3vHjh7","outputId":"971f6a2e-e9fc-4c4a-a598-1eb5eb722292"},"outputs":[{"name":"stdout","output_type":"stream","text":["images.keys: dict_keys(['21[21] _2', '5[5]', '19[19]', '17[17]__', '15[15]', '3[3]', '11[11]', '7[7]', '13[13]', '14[14]', '4[4]', '9[9]', '20[20]_2', '8[8]', '12[12]', '6[6]', '1[1]', '2[2]'])\n","Image Format: JPEG\n","Image Mode: RGB\n","Image Size: (512, 512) pixels (Width: 512, Height: 512)\n","Image Colors: [(8111, (255, 255, 255)), (356, (253, 253, 253)), (305, (251, 251, 251)), (254, (249, 249, 249)), (220, (247, 247, 247)), (168, (245, 245, 245)), (133, (243, 243, 243)), (130, (241, 241, 241)), (108, (239, 239, 239)), (108, (237, 237, 237)), (77, (235, 235, 235)), (96, (233, 233, 233)), (87, (231, 231, 231)), (81, (229, 229, 229)), (92, (227, 227, 227)), (93, (225, 225, 225)), (76, (223, 223, 223)), (79, (221, 221, 221)), (102, (219, 219, 219)), (107, (217, 217, 217)), (120, (215, 215, 215)), (108, (213, 213, 213)), (141, (211, 211, 211)), (126, (209, 209, 209)), (150, (207, 207, 207)), (172, (205, 205, 205)), (164, (203, 203, 203)), (190, (201, 201, 201)), (236, (199, 199, 199)), (245, (197, 197, 197)), (261, (195, 195, 195)), (334, (193, 193, 193)), (339, (191, 191, 191)), (376, (189, 189, 189)), (445, (187, 187, 187)), (414, (185, 185, 185)), (464, (183, 183, 183)), (463, (181, 181, 181)), (502, (179, 179, 179)), (557, (177, 177, 177)), (543, (175, 175, 175)), (507, (173, 173, 173)), (551, (171, 171, 171)), (576, (169, 169, 169)), (524, (167, 167, 167)), (503, (165, 165, 165)), (508, (163, 163, 163)), (511, (161, 161, 161)), (476, (159, 159, 159)), (410, (157, 157, 157)), (446, (155, 155, 155)), (450, (153, 153, 153)), (418, (151, 151, 151)), (446, (149, 149, 149)), (376, (147, 147, 147)), (397, (145, 145, 145)), (423, (143, 143, 143)), (419, (141, 141, 141)), (386, (139, 139, 139)), (339, (137, 137, 137)), (356, (135, 135, 135)), (326, (133, 133, 133)), (332, (131, 131, 131)), (309, (129, 129, 129)), (327, (127, 127, 127)), (315, (125, 125, 125)), (326, (123, 123, 123)), (291, (121, 121, 121)), (277, (119, 119, 119)), (250, (117, 117, 117)), (260, (115, 115, 115)), (259, (113, 113, 113)), (238, (111, 111, 111)), (242, (109, 109, 109)), (249, (107, 107, 107)), (240, (105, 105, 105)), (242, (103, 103, 103)), (213, (101, 101, 101)), (231, (99, 99, 99)), (218, (97, 97, 97)), (220, (95, 95, 95)), (264, (93, 93, 93)), (248, (91, 91, 91)), (242, (89, 89, 89)), (236, (87, 87, 87)), (225, (85, 85, 85)), (250, (83, 83, 83)), (242, (81, 81, 81)), (237, (79, 79, 79)), (213, (77, 77, 77)), (218, (75, 75, 75)), (236, (73, 73, 73)), (224, (71, 71, 71)), (204, (69, 69, 69)), (224, (67, 67, 67)), (214, (65, 65, 65)), (210, (63, 63, 63)), (198, (61, 61, 61)), (199, (59, 59, 59)), (229, (57, 57, 57)), (188, (55, 55, 55)), (176, (53, 53, 53)), (201, (51, 51, 51)), (190, (49, 49, 49)), (200, (47, 47, 47)), (187, (45, 45, 45)), (194, (43, 43, 43)), (192, (41, 41, 41)), (185, (39, 39, 39)), (196, (37, 37, 37)), (185, (35, 35, 35)), (204, (33, 33, 33)), (172, (31, 31, 31)), (210, (29, 29, 29)), (208, (27, 27, 27)), (194, (25, 25, 25)), (203, (23, 23, 23)), (190, (21, 21, 21)), (212, (19, 19, 19)), (248, (17, 17, 17)), (262, (15, 15, 15)), (300, (13, 13, 13)), (377, (11, 11, 11)), (489, (9, 9, 9)), (632, (7, 7, 7)), (821, (5, 5, 5)), (1074, (3, 3, 3)), (171117, (1, 1, 1)), (371, (254, 254, 254)), (340, (252, 252, 252)), (302, (250, 250, 250)), (207, (248, 248, 248)), (188, (246, 246, 246)), (168, (244, 244, 244)), (138, (242, 242, 242)), (143, (240, 240, 240)), (104, (238, 238, 238)), (111, (236, 236, 236)), (91, (234, 234, 234)), (86, (232, 232, 232)), (95, (230, 230, 230)), (90, (228, 228, 228)), (73, (226, 226, 226)), (100, (224, 224, 224)), (81, (222, 222, 222)), (99, (220, 220, 220)), (103, (218, 218, 218)), (129, (216, 216, 216)), (118, (214, 214, 214)), (123, (212, 212, 212)), (138, (210, 210, 210)), (134, (208, 208, 208)), (142, (206, 206, 206)), (175, (204, 204, 204)), (207, (202, 202, 202)), (203, (200, 200, 200)), (220, (198, 198, 198)), (278, (196, 196, 196)), (317, (194, 194, 194)), (338, (192, 192, 192)), (375, (190, 190, 190)), (387, (188, 188, 188)), (425, (186, 186, 186)), (385, (184, 184, 184)), (460, (182, 182, 182)), (527, (180, 180, 180)), (537, (178, 178, 178)), (559, (176, 176, 176)), (552, (174, 174, 174)), (557, (172, 172, 172)), (524, (170, 170, 170)), (547, (168, 168, 168)), (526, (166, 166, 166)), (546, (164, 164, 164)), (538, (162, 162, 162)), (486, (160, 160, 160)), (484, (158, 158, 158)), (475, (156, 156, 156)), (463, (154, 154, 154)), (417, (152, 152, 152)), (413, (150, 150, 150)), (423, (148, 148, 148)), (383, (146, 146, 146)), (382, (144, 144, 144)), (402, (142, 142, 142)), (338, (140, 140, 140)), (382, (138, 138, 138)), (333, (136, 136, 136)), (330, (134, 134, 134)), (311, (132, 132, 132)), (275, (130, 130, 130)), (307, (128, 128, 128)), (312, (126, 126, 126)), (299, (124, 124, 124)), (307, (122, 122, 122)), (306, (120, 120, 120)), (264, (118, 118, 118)), (259, (116, 116, 116)), (247, (114, 114, 114)), (245, (112, 112, 112)), (270, (110, 110, 110)), (242, (108, 108, 108)), (208, (106, 106, 106)), (250, (104, 104, 104)), (219, (102, 102, 102)), (237, (100, 100, 100)), (228, (98, 98, 98)), (261, (96, 96, 96)), (213, (94, 94, 94)), (218, (92, 92, 92)), (226, (90, 90, 90)), (205, (88, 88, 88)), (255, (86, 86, 86)), (241, (84, 84, 84)), (241, (82, 82, 82)), (251, (80, 80, 80)), (241, (78, 78, 78)), (265, (76, 76, 76)), (246, (74, 74, 74)), (215, (72, 72, 72)), (197, (70, 70, 70)), (208, (68, 68, 68)), (219, (66, 66, 66)), (241, (64, 64, 64)), (192, (62, 62, 62)), (222, (60, 60, 60)), (170, (58, 58, 58)), (185, (56, 56, 56)), (206, (54, 54, 54)), (202, (52, 52, 52)), (195, (50, 50, 50)), (217, (48, 48, 48)), (201, (46, 46, 46)), (201, (44, 44, 44)), (198, (42, 42, 42)), (175, (40, 40, 40)), (190, (38, 38, 38)), (182, (36, 36, 36)), (195, (34, 34, 34)), (184, (32, 32, 32)), (163, (30, 30, 30)), (196, (28, 28, 28)), (186, (26, 26, 26)), (196, (24, 24, 24)), (203, (22, 22, 22)), (227, (20, 20, 20)), (217, (18, 18, 18)), (243, (16, 16, 16)), (275, (14, 14, 14)), (327, (12, 12, 12)), (433, (10, 10, 10)), (530, (8, 8, 8)), (751, (6, 6, 6)), (977, (4, 4, 4)), (1185, (2, 2, 2)), (10783, (0, 0, 0))]\n"]}],"source":["from PIL import Image\n","\n","def get_image_specifications(image_path):\n","    # Open the image file\n","    with Image.open(image_path) as img:\n","        # Get image specifications\n","        image_format = img.format\n","        image_mode = img.mode\n","        image_size = img.size\n","        image_width, image_height = img.size\n","        image_color = img.getcolors()\n","\n","    return f\"Image Format: {image_format}\\nImage Mode: {image_mode}\\nImage Size: {image_size} pixels (Width: {image_width}, Height: {image_height})\\nImage Colors: {image_color}\"\n","\n","# Example usage:\n","print('images.keys:', images.keys())\n","image_path = \"/content/Brain-CT-Hemorrhage-Dataset/dataset/Hemorrhagic/KANAMA/11[11]/11_0_0.jpg\"\n","# print('image_path:',image_path := images['normal'][0].path)\n","image_specifications = get_image_specifications(image_path)\n","print(image_specifications)"]},{"cell_type":"markdown","metadata":{"id":"pNqGxruI1TIA"},"source":["## Noise Metrics"]},{"cell_type":"markdown","metadata":{"id":"oTx-EMV9f1vC"},"source":["GitHub Copilot: The evaluation metrics indicate that both the Github Copilot's code and ChatGPT's code have successfully reduced the noise in the image, as evidenced by the non-infinite PSNR and non-zero RMSE values.\n","\n","The PSNR (Peak Signal-to-Noise Ratio) is a measure of the peak error. The fact that PSNR is infinite for the original image indicates there's no noise (as it's being compared with itself), while for the processed images, the PSNR values are finite and quite high, indicating a low level of distortion.\n","\n","The RMSE (Root Mean Square Error) is a quadratic scoring rule that measures the average magnitude of the error. The fact that RMSE is zero for the original image indicates there's no error (as it's being compared with itself), while for the processed images, the RMSE values are non-zero but quite low, indicating a low level of error.\n","\n","The SNR (Signal-to-Noise Ratio) is a measure of signal strength relative to background noise. The negative SNR values indicate that the noise is stronger than the signal, which is not ideal. However, the SNR values have increased (become less negative) from the original to the processed images, indicating that the signal has become stronger relative to the noise.\n","\n","In terms of comparison between Github Copilot's code and ChatGPT's code, the metrics are quite similar, but ChatGPT's code has slightly better PSNR and RMSE values, indicating slightly less distortion and error. However, the differences are quite small and may not be noticeable in the image quality.\n","\n","GitHub Copilot: Dĩ nhiên, dưới đây là các định nghĩa bằng tiếng Việt:\n","\n","1. PSNR (Peak Signal-to-Noise Ratio - Tỉ lệ tín hiệu so với nhiễu): PSNR là một độ đo chất lượng của hình ảnh đã được khôi phục so với hình ảnh gốc. PSNR càng cao, chất lượng hình ảnh khôi phục càng tốt và càng giống với hình ảnh gốc.\n","\n","2. RMSE (Root Mean Square Error - Sai số bình phương trung bình): RMSE là một độ đo sự khác biệt giữa các giá trị dự đoán bởi một mô hình và các giá trị thực tế. RMSE càng thấp, mô hình dự đoán càng chính xác.\n","\n","3. SNR (Signal-to-Noise Ratio - Tỉ lệ tín hiệu so với nhiễu): SNR là một độ đo chất lượng tín hiệu so với nhiễu. SNR càng cao, chất lượng tín hiệu càng tốt và nhiễu càng ít.\n","\n","Lưu ý rằng, mặc dù PSNR, RMSE, và SNR cao thường cho thấy chất lượng hình ảnh tốt hơn, nhưng chúng không phải lúc nào cũng dẫn đến độ chính xác cao hơn trong các tác vụ phân loại."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQVJK9u51SWF"},"outputs":[],"source":["from skimage.metrics import peak_signal_noise_ratio, mean_squared_error\n","\n","def calculate_metrics(original, processed):\n","    # Github Copilot\n","    # Calculate the PSNR\n","    psnr = peak_signal_noise_ratio(original, processed)\n","\n","    # Calculate the RMSE\n","    rmse = np.sqrt(mean_squared_error(original, processed))\n","\n","    # Calculate the SNR\n","    mean = np.mean(processed)\n","    std = np.std(processed)\n","    snr = 20 * np.log10(mean / (std + 1e-10)) # 1e-10: avoid error std=0\n","\n","    # # ChatGPT\n","    # mse = np.mean((original - processed)**2)\n","    # rmse = np.sqrt(mse)\n","    # psnr = 20 * np.log10(255 / rmse)  # Assuming pixel values range from 0 to 255\n","    # # snr = 10 * np.log10(np.sum(original**2) / mse)\n","    # snr = np.mean(original) / np.std(original - processed)\n","\n","    return psnr, rmse, snr"]},{"cell_type":"markdown","metadata":{"id":"h1B9CcpywazV"},"source":["It looks like you've provided information about three different image quality metrics: PSNR (Peak Signal-to-Noise Ratio), MSE (Mean Squared Error), and AMBE (Absolute Mean Brightness Error). These metrics are commonly used for assessing the quality of reconstructed or processed images. Let me explain each of them briefly:\n","\n","### 1. Peak Signal-to-Noise Ratio (PSNR):\n","\n","PSNR is a measure of the quality of a reconstructed or processed image. It is expressed in decibels (dB) and is calculated using the formula:\n","\n","$$ PSNR = 10 \\cdot \\log_{10}\\left(\\frac{{\\text{Max Value}^2}}{{\\text{MSE}}}\\right) $$\n","\n","Where:\n","- $\\text{Max Value}$ is the maximum pixel value of the image (usually 255 for 8-bit images).\n","- $\\text{MSE}$ is the Mean Squared Error between the original and processed images.\n","\n","### 2. Mean Squared Error (MSE):\n","\n","MSE is a measure of the average squared differences between corresponding pixels of the original and processed images. It is calculated using the formula:\n","\n","$$ MSE = \\frac{1}{N \\times M} \\sum_{i=1}^{N} \\sum_{j=1}^{M} (I(i, j) - P(i, j))^2 $$\n","\n","Where:\n","- $N$ and $M$ are the dimensions of the images.\n","- $I(i, j)$ is the intensity of the pixel at position $(i, j)$ in the original image.\n","- $P(i, j)$ is the intensity of the pixel at position $(i, j)$ in the processed image.\n","\n","### 3. Absolute Mean Brightness Error (AMBE):\n","\n","AMBE measures the contrast between the initial image's brightness and the improved image's brightness. It is given by the formula:\n","\n","$$ AMBE = \\frac{1}{N \\times M} \\sum_{i=1}^{N} \\sum_{j=1}^{M} |I(i, j) - P(i, j)| $$\n","\n","Where:\n","- $N$ and $M$ are the dimensions of the images.\n","- $I(i, j)$ is the intensity of the pixel at position $(i, j)$ in the original image.\n","- $P(i, j)$ is the intensity of the pixel at position $(i, j)$ in the processed image.\n","\n","These metrics are commonly used for image quality assessment, and you can implement them using the appropriate formulas in your chosen programming language (such as Python). If you have specific questions or need code examples, feel free to ask!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8OVG7s7xa2r"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","def calculate_metrics(original_image, processed_image):\n","    # # Load images\n","    # original_image = cv2.imread(original_image_path, cv2.IMREAD_GRAYSCALE)\n","    # processed_image = cv2.imread(processed_image_path, cv2.IMREAD_GRAYSCALE)\n","\n","    # # Ensure both images have the same dimensions\n","    # if original_image.shape != processed_image.shape:\n","    #     raise ValueError(\"Original and processed images must have the same dimensions.\")\n","\n","    # Maximum pixel value (usually 255 for 8-bit images)\n","    max_pixel_value = 255\n","\n","    # Calculate Mean Squared Error (MSE)\n","    mse = np.mean((original_image - processed_image) ** 2)\n","    rmse = np.sqrt(mse)\n","    # # Dimensions of the images\n","    # N, M = original_image.shape\n","    # # Calculate Mean Squared Error (MSE)\n","    # mse = np.sum((original_image - processed_image)**2) / (N * M)\n","\n","    # Calculate Peak Signal-to-Noise Ratio (PSNR)\n","    psnr = 10 * np.log10(max_pixel_value**2 / mse)\n","\n","    # Calculate Absolute Mean Brightness Error (AMBE)\n","    ambe = np.mean(np.abs(original_image - processed_image))\n","\n","    return psnr, mse, rmse, ambe\n"]},{"cell_type":"markdown","metadata":{"id":"7rsuJMU1hEgO"},"source":["## Original"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_fuVo6WvFHA8"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from shutil import copyfile\n","\n","def preprocess_and_copy(src_dir, dest_dir, preprocess_func):\n","    # Check if src_dir is a directory\n","    if os.path.isdir(src_dir):\n","        # If dest_dir does not exist, create it\n","        os.makedirs(dest_dir, exist_ok=True)\n","\n","        # Iterate over files/directories in src_dir\n","        for item in os.listdir(src_dir):\n","            src_item_path = os.path.join(src_dir, item)\n","            dest_item_path = os.path.join(dest_dir, item)\n","\n","            # If item is a directory, call function recursively\n","            if os.path.isdir(src_item_path):\n","                preprocess_and_copy(src_item_path, dest_item_path, preprocess_func)\n","            # If item is a file, apply preprocessing and copy\n","            elif os.path.isfile(src_item_path):\n","                img = cv2.imread(src_item_path)\n","                if img is not None:\n","                    img = preprocess_func(img)\n","                    cv2.imwrite(dest_item_path, img)\n","\n","# Define your preprocessing function here\n","def preprocess_func(img):\n","    # TODO: Add your preprocessing steps here\n","    return img\n","\n","# Usage:\n","dataset_path = '/content/Brain-CT-Hemorrhage-Dataset/sample'\n","# dataset_path = '/content/Brain-CT-Hemorrhage-Dataset/dataset'\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Thesis/Preprocessing/Brain-CT-Hemorrhage-Dataset/Original'\n","preprocess_and_copy(dataset_path, output_path, preprocess_func)"]},{"cell_type":"markdown","metadata":{"id":"heEN-1SZ-kHb"},"source":["## CLAHE + median filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJ_E28m_IrJ6"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from shutil import copyfile\n","\n","def preprocess_and_copy(src_dir, dest_dir, preprocess_func):\n","    # Check if src_dir is a directory\n","    if os.path.isdir(src_dir):\n","        # If dest_dir does not exist, create it\n","        os.makedirs(dest_dir, exist_ok=True)\n","\n","        # Iterate over files/directories in src_dir\n","        for item in os.listdir(src_dir):\n","            src_item_path = os.path.join(src_dir, item)\n","\n","            # If item is a directory, call function recursively\n","            if os.path.isdir(src_item_path):\n","                preprocess_and_copy(src_item_path, os.path.join(dest_dir, item), preprocess_func)\n","            # If item is a file, apply preprocessing and copy\n","            elif os.path.isfile(src_item_path):\n","                # Define the output file path\n","                filename_with_ext = os.path.basename(src_item_path)\n","                filename, extension = os.path.splitext(filename_with_ext)\n","                dest_item_path = os.path.join(dest_dir, filename + '.jpg')\n","\n","                # Check if output file already exists\n","                if not os.path.exists(dest_item_path):\n","                    img = cv2.imread(src_item_path)\n","                    if img is not None:\n","                        img = preprocess_func(img)\n","\n","                        # Export the preprocessed image to the output folder\n","                        cv2.imwrite(dest_item_path, img)\n","\n","# Define your preprocessing function here\n","def preprocess_func(img):\n","    # TODO: Add your preprocessing steps here\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n","    # create a CLAHE object (Arguments are optional).\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","    cl1 = clahe.apply(gray)\n","\n","    # Apply median filter\n","    median = cv2.medianBlur(cl1, 3)\n","\n","    return median\n","\n","# Usage:\n","# dataset_path = '/content/Brain-CT-Hemorrhage-Dataset/sample'\n","# output_path = '/content/drive/MyDrive/Colab Notebooks/Thesis/Preprocessing/Brain-CT-Hemorrhage-Dataset/CLAHE_medianF3x3_sample'\n","dataset_path = '/content/Brain-CT-Hemorrhage-Dataset/dataset'\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Thesis/Preprocessing/Brain-CT-Hemorrhage-Dataset/CLAHE_medianF3x3'\n","preprocess_and_copy(dataset_path, output_path, preprocess_func)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
